{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hello, all","title":"Home"},{"location":"about/","text":"","title":"K-Means"},{"location":"About/license/","text":"Skipped.","title":"License"},{"location":"About/release-notes/","text":"Skipped.","title":"Release notes"},{"location":"Documentations/blob-storage/","text":"","title":"azure blob storage"},{"location":"Documentations/mk-docs/","text":"Links For full documentation visit mkdocs.org . This is the pheasants documentation link . For full documentation visit [mkdocs.org](https://www.mkdocs.org). <br> This is the pheasants documentation [link](https://pheasant.daizutabi.net/). This command will give you line break ------------ Commands `mkdocs new [dir-name]` - Create a **new** project. mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. mkdocs gh-deploy - Deploy to the server also this gives you bullet points Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Also identation will give you space to write code like this a very important message or def fn(): pass [1] 2021-04-26 10:53:10 ( 94.0ms ) python3 ( 1.24s ) ```python def fn(): pass ``` Table 1 Adding a markdown table First Header Second Header Third Header Content Cell Content Cell Content Cell Content Cell Content Cell Content Cell #Table Adding a markdown table First Header | Second Header | Third Header ------------ | ------------- | ------------ Content Cell | Content Cell | Content Cell Content Cell | Content Cell | Content Cell Figure 1 Linking a video #Fig Linking a video [1](mk-docs.md#hylink) <p align=\"center\"> <iframe height=\"480\" width=\"900\" allow=\"fullscreen;\" src=\"https://www.youtube.com/embed/aNLIWvk2CRY\"> </iframe> </p> Figure 2 A Matplotlib figure generated from a python code Linking something back, 1 Figure 3 Adding immages Figure 4 Adding two figures with a blank line","title":"mk-docs"},{"location":"Documentations/mk-docs/#links","text":"For full documentation visit mkdocs.org . This is the pheasants documentation link . For full documentation visit [mkdocs.org](https://www.mkdocs.org). <br> This is the pheasants documentation [link](https://pheasant.daizutabi.net/).","title":"Links"},{"location":"Documentations/mk-docs/#this-command-will-give-you-line-break","text":"------------","title":"This command will give you line break"},{"location":"Documentations/mk-docs/#commands","text":"`mkdocs new [dir-name]` - Create a **new** project. mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. mkdocs gh-deploy - Deploy to the server also this gives you bullet points","title":"Commands"},{"location":"Documentations/mk-docs/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Also identation will give you space to write code like this a very important message or def fn(): pass [1] 2021-04-26 10:53:10 ( 94.0ms ) python3 ( 1.24s ) ```python def fn(): pass ``` Table 1 Adding a markdown table First Header Second Header Third Header Content Cell Content Cell Content Cell Content Cell Content Cell Content Cell #Table Adding a markdown table First Header | Second Header | Third Header ------------ | ------------- | ------------ Content Cell | Content Cell | Content Cell Content Cell | Content Cell | Content Cell Figure 1 Linking a video #Fig Linking a video [1](mk-docs.md#hylink) <p align=\"center\"> <iframe height=\"480\" width=\"900\" allow=\"fullscreen;\" src=\"https://www.youtube.com/embed/aNLIWvk2CRY\"> </iframe> </p> Figure 2 A Matplotlib figure generated from a python code Linking something back, 1 Figure 3 Adding immages Figure 4 Adding two figures with a blank line","title":"Project layout"},{"location":"Misc/email_notifications/","text":"Introduction This page will guide you on how to send out email notifications using python. Step-1 Need to enable \"Less secure app access\" in google account settings from the sender's email address. For that go to this link and enable it. Step-2 Once that's done, open the python termainal and run this code with the appropriate values. Make sure you make your passwords as environment variables otherwise your google account might get hacked. # Importing packages import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText # The mail addresses and password sender_address = 'id@gmail.com' sender_pass = 'passwords' receiver_address = 'id@gmail.com' # can be any id # Content mail_content = \"\"\"content\"\"\" subject = \"\"\"subject\"\"\" def send_email_gmail(sender_address, sender_pass, receiver_address, mail_content, subject): #Setup the MIME message = MIMEMultipart() message['From'] = sender_address message['To'] = receiver_address message['Subject'] = subject #The subject line #The body and the attachments for the mail message.attach(MIMEText(mail_content, 'plain')) #Create SMTP session for sending the mail session = smtplib.SMTP('smtp.gmail.com', 587) #use gmail with port # session = smtplib.SMTP('smtp-mail.outlook.com', 587) session.starttls() #enable security session.login(sender_address, sender_pass) #login with mail_id and password text = message.as_string() session.sendmail(sender_address, receiver_address, text) session.quit() send_email_gmail(sender_address, sender_pass, receiver_address, mail_content, subject) [1] ( ) ( ) Requirements cachetools==4.2.1 certifi==2020.12.5 chardet==4.0.0 cssselect==1.1.0 cssutils==2.2.0 email-to==0.1.0 idna==2.10 lxml==4.6.3 Markdown==3.3.4 premailer==3.8.0 requests==2.25.1 urllib3==1.26.4","title":"Email Notifications"},{"location":"Misc/email_notifications/#introduction","text":"This page will guide you on how to send out email notifications using python.","title":"Introduction"},{"location":"Misc/email_notifications/#step-1","text":"Need to enable \"Less secure app access\" in google account settings from the sender's email address. For that go to this link and enable it.","title":"Step-1"},{"location":"Misc/email_notifications/#step-2","text":"Once that's done, open the python termainal and run this code with the appropriate values. Make sure you make your passwords as environment variables otherwise your google account might get hacked. # Importing packages import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText # The mail addresses and password sender_address = 'id@gmail.com' sender_pass = 'passwords' receiver_address = 'id@gmail.com' # can be any id # Content mail_content = \"\"\"content\"\"\" subject = \"\"\"subject\"\"\" def send_email_gmail(sender_address, sender_pass, receiver_address, mail_content, subject): #Setup the MIME message = MIMEMultipart() message['From'] = sender_address message['To'] = receiver_address message['Subject'] = subject #The subject line #The body and the attachments for the mail message.attach(MIMEText(mail_content, 'plain')) #Create SMTP session for sending the mail session = smtplib.SMTP('smtp.gmail.com', 587) #use gmail with port # session = smtplib.SMTP('smtp-mail.outlook.com', 587) session.starttls() #enable security session.login(sender_address, sender_pass) #login with mail_id and password text = message.as_string() session.sendmail(sender_address, receiver_address, text) session.quit() send_email_gmail(sender_address, sender_pass, receiver_address, mail_content, subject) [1] ( ) ( )","title":"Step-2"},{"location":"Misc/email_notifications/#requirements","text":"cachetools==4.2.1 certifi==2020.12.5 chardet==4.0.0 cssselect==1.1.0 cssutils==2.2.0 email-to==0.1.0 idna==2.10 lxml==4.6.3 Markdown==3.3.4 premailer==3.8.0 requests==2.25.1 urllib3==1.26.4","title":"Requirements"},{"location":"Technology/SQL/Indexing/","text":"head Why is it needed? When data is stored on disk-based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously. Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isn\u2019t sorted requires a Linear Search which requires N/2 block accesses (on average), where N is the number of blocks that the table spans. If that field is a non-key field (i.e. doesn\u2019t contain unique entries) then the entire tablespace must be searched at N block accesses. Whereas with a sorted field, a Binary Search may be used, which has log2 N block accesses. Also since the data is sorted given a non-key field, the rest of the table doesn\u2019t need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial. What is indexing? Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and a pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it. The downside to indexing is that these indices require additional space on the disk since the indices are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed. How does it work? Firstly, let\u2019s outline a sample database table schema; Field name Data type Size on disk id (Primary key) Unsigned INT 4 bytes firstName Char(50) 50 bytes lastName Char(50) 50 bytes emailAddress Char(100) 100 bytes Note: char was used in place of varchar to allow for an accurate size on disk value. This sample database contains five million rows and is unindexed. The performance of several queries will now be analyzed. These are a query using the id (a sorted key field) and one using the firstName (a non-key unsorted field). Example 1 - sorted vs unsorted fields Given our sample database of r = 5,000,000 records of a fixed size giving a record length of R = 204 bytes and they are stored in a table using the MyISAM engine which is using the default block size B = 1,024 bytes. The blocking factor of the table would be bfr = (B/R) = 1024/204 = 5 records per disk block. The total number of blocks required to hold the table is N = (r/bfr) = 5000000/5 = 1,000,000 blocks. A linear search on the id field would require an average of N/2 = 500,000 block accesses to find a value, given that the id field is a key field. But since the id field is also sorted, a binary search can be conducted requiring an average of log2 1000000 = 19.93 = 20 block accesses. Instantly we can see this is a drastic improvement. Now the firstName field is neither sorted nor a key field, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact N = 1,000,000 block accesses. It is this situation that indexing aims to correct. Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks than the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the firstName field is outlined below; Field name Data type Size on disk firstName Char(50) 50 bytes (record pointer) Special 4 bytes Note: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table. Example 2 - indexing Given our sample database of r = 5,000,000 records with an index record length of R = 54 bytes and using the default block size B = 1,024 bytes. The blocking factor of the index would be bfr = (B/R) = 1024/54 = 18 records per disk block. The total number of blocks required to hold the index is N = (r/bfr) = 5000000/18 = 277,778 blocks. Now a search using the firstName field can utilize the index to increase performance. This allows for a binary search of the index with an average of log2 277778 = 18.08 = 19 block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to 19 + 1 = 20 block accesses, a far cry from the 1,000,000 block accesses required to find a firstName match in the non-indexed table. When should it be used? Given that creating an index requires additional disk space (277,778 blocks extra from the above example, a ~28% increase), and that too many indices can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index. Since indices are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space.","title":"Indexing"},{"location":"Technology/SQL/Indexing/#head","text":"Why is it needed? When data is stored on disk-based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously. Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isn\u2019t sorted requires a Linear Search which requires N/2 block accesses (on average), where N is the number of blocks that the table spans. If that field is a non-key field (i.e. doesn\u2019t contain unique entries) then the entire tablespace must be searched at N block accesses. Whereas with a sorted field, a Binary Search may be used, which has log2 N block accesses. Also since the data is sorted given a non-key field, the rest of the table doesn\u2019t need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial. What is indexing? Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and a pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it. The downside to indexing is that these indices require additional space on the disk since the indices are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed. How does it work? Firstly, let\u2019s outline a sample database table schema; Field name Data type Size on disk id (Primary key) Unsigned INT 4 bytes firstName Char(50) 50 bytes lastName Char(50) 50 bytes emailAddress Char(100) 100 bytes Note: char was used in place of varchar to allow for an accurate size on disk value. This sample database contains five million rows and is unindexed. The performance of several queries will now be analyzed. These are a query using the id (a sorted key field) and one using the firstName (a non-key unsorted field). Example 1 - sorted vs unsorted fields Given our sample database of r = 5,000,000 records of a fixed size giving a record length of R = 204 bytes and they are stored in a table using the MyISAM engine which is using the default block size B = 1,024 bytes. The blocking factor of the table would be bfr = (B/R) = 1024/204 = 5 records per disk block. The total number of blocks required to hold the table is N = (r/bfr) = 5000000/5 = 1,000,000 blocks. A linear search on the id field would require an average of N/2 = 500,000 block accesses to find a value, given that the id field is a key field. But since the id field is also sorted, a binary search can be conducted requiring an average of log2 1000000 = 19.93 = 20 block accesses. Instantly we can see this is a drastic improvement. Now the firstName field is neither sorted nor a key field, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact N = 1,000,000 block accesses. It is this situation that indexing aims to correct. Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks than the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the firstName field is outlined below; Field name Data type Size on disk firstName Char(50) 50 bytes (record pointer) Special 4 bytes Note: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table. Example 2 - indexing Given our sample database of r = 5,000,000 records with an index record length of R = 54 bytes and using the default block size B = 1,024 bytes. The blocking factor of the index would be bfr = (B/R) = 1024/54 = 18 records per disk block. The total number of blocks required to hold the index is N = (r/bfr) = 5000000/18 = 277,778 blocks. Now a search using the firstName field can utilize the index to increase performance. This allows for a binary search of the index with an average of log2 277778 = 18.08 = 19 block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to 19 + 1 = 20 block accesses, a far cry from the 1,000,000 block accesses required to find a firstName match in the non-indexed table. When should it be used? Given that creating an index requires additional disk space (277,778 blocks extra from the above example, a ~28% increase), and that too many indices can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index. Since indices are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space.","title":"head"},{"location":"algorithms/clustering/local_outlier_detection/","text":"Introduction compares local density of the outliers to the local density of its K neighbours if a points local density is significantly lower than its K nearest neighbours, it can be called as an anomaly this density is calculated by the inverse of the reachability distance Selection criteria used when the anomaly is very close to the actual points but less densely packed will flag high density and sparse clusters as normal, but a loose point near a dense cluster as an anomaly How it works? Considering a dataset which has already formed clusters import matplotlib.pyplot as plt import numpy as np import pandas as pd # Generate normal (not abnormal) training observations X = 0.3 * np.random.randn(100, 2) # create a normal distribution between 0 and 1 of the required shape X_train = np.r_[X + 2, X - 2] # concat multiple array's of the same shape together # Generate new normal (not abnormal) observations X = 0.3 * np.random.randn(20, 2) X_test = np.r_[X + 2, X - 2] # Generate some abnormal novel observations X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2)) df = pd.DataFrame(np.r_[X_train, X_test, X_outliers], columns = ['x', 'y']) df.head() [1] 2021-04-26 11:31:08 ( 104ms ) python3 ( 3.32s ) x y 0 1.448091 2.500459 1 1.589671 1.691205 2 2.283369 2.543845 3 2.314729 2.030218 4 2.248377 1.986990 plt.scatter(df['x'], df['y']) plt.show() [2] 2021-04-26 11:31:08 ( 190ms ) python3 ( 3.51s ) Step 1: Find K nearest datapoints using eucleidian distance from the point under consideration, we are assuming K to be 3 in this case # Getting indices for each of the point temp = df[['x', 'y']].reset_index() # Applying cross join to calculate Euclidean distance # Adding 0 column for cross join temp[0] = 0 temp = pd.merge(temp, temp, how = 'outer', on = 0) # Dropping 0 column del temp[0] # Calculating Euclidean distance temp['eu_dist'] = ((temp['x_x'] - temp['x_y'])**2 + (temp['y_x'] - temp['y_y'])**2)**0.5 # Dropping zero values because they will be same point temp = temp[temp['eu_dist'] != 0] # Adding a rank by distance to each datapoint to get the closest K datapoint temp[\"rank\"] = temp.groupby(\"index_x\")[\"eu_dist\"].rank(\"min\", ascending=True) #let k = 2 k = 3 temp = temp[temp['rank'] <=k] temp.head() [3] 2021-04-26 11:40:47 ( 139ms ) python3 ( 785ms ) NameError: name 'df' is not defined NameError Traceback (most recent call last) <ipython-input-10-8f43e2957478> in <module> 1 # Getting indices for each of the point ----> 2 temp = df[['x', 'y']].reset_index() 3 4 # Applying cross join to calculate Euclidean distance 5 # Adding 0 column for cross join Step 2: Calculate reachability distance from the considered point to its neighbours (which also equals the maximum distance between Kth distance of the other point or the euclidian distance of that point) # Sorting values to get the kth distance for each point temp_2 = temp.sort_values(['index_x', 'eu_dist'], ascending = [True,False]).reset_index(drop = True)[['index_x', 'index_y','eu_dist']] # Getting the kth value min_indices = [] for i in np.unique(np.array(temp_2['index_x'])): min_indices.append(min(temp_2[temp_2['index_x'] == i].index)) kth_distance = temp_2[temp_2.index.isin(min_indices)] kth_distance = kth_distance.rename(columns={\"eu_dist\": \"kth_dist\", \"index_x\": \"point_label\"}) del kth_distance['index_y'] kth_distance.head() [4] 2021-04-26 11:40:47 ( 255ms ) python3 ( 1.04s ) NameError: name 'temp' is not defined NameError Traceback (most recent call last) <ipython-input-11-a3e6eabb29b3> in <module> 1 # Sorting values to get the kth distance for each point ----> 2 temp_2 = temp.sort_values(['index_x', 'eu_dist'], ascending = [True,False]).reset_index(drop = True)[['index_x', 'index_y','eu_dist']] 3 4 # Getting the kth value 5 min_indices = [] # Calculating reachability distance reach_dist = pd.merge(temp_2, kth_distance, left_on = 'index_y', right_on= 'point_label', how = 'left') del reach_dist['point_label'] reach_dist['rd'] = reach_dist[['eu_dist','kth_dist']].max(axis = 1) del reach_dist['eu_dist'] del reach_dist['kth_dist'] reach_dist.head() [5] 2021-04-26 11:40:47 ( 157ms ) python3 ( 1.20s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-12-71b6a020d6dd> in <module> 1 # Calculating reachability distance ----> 2 reach_dist = pd.merge(temp_2, kth_distance, left_on = 'index_y', right_on= 'point_label', how = 'left') 3 del reach_dist['point_label'] 4 5 reach_dist['rd'] = reach_dist[['eu_dist','kth_dist']].max(axis = 1) mean_rd = pd.DataFrame(reach_dist.groupby(['index_x'])['rd'].mean()).reset_index() mean_rd = mean_rd.rename(columns={\"index_x\": \"point_label\"}) mean_rd.head() [6] 2021-04-26 11:40:47 ( 105ms ) python3 ( 1.30s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-13-637b1bcafcd4> in <module> ----> 1 mean_rd = pd.DataFrame(reach_dist.groupby(['index_x'])['rd'].mean()).reset_index() 2 3 mean_rd = mean_rd.rename(columns={\"index_x\": \"point_label\"}) 4 mean_rd.head() Step 3: Calculate local reachability density # Getting LRD(local reachability density) for individual points lrd_all_pts = mean_rd.copy() lrd_all_pts['lrd'] = 1/lrd_all_pts['rd'] del lrd_all_pts['rd'] lrd_all_pts.head() [7] 2021-04-26 11:40:47 ( 105ms ) python3 ( 1.41s ) NameError: name 'mean_rd' is not defined NameError Traceback (most recent call last) <ipython-input-14-9fc93de50496> in <module> 1 # Getting LRD(local reachability density) for individual points ----> 2 lrd_all_pts = mean_rd.copy() 3 lrd_all_pts['lrd'] = 1/lrd_all_pts['rd'] 4 del lrd_all_pts['rd'] 5 # Getting average LRD from all the neighbours avg_lrd = pd.merge(temp_2[['index_x', 'index_y']], lrd_all_pts, left_on = 'index_y', right_on = 'point_label', how = 'left') avg_lrd = pd.DataFrame(avg_lrd.groupby(['index_x'])['lrd'].mean()).reset_index() avg_lrd = avg_lrd.rename({\"index_x\":\"point_label\", \"lrd\":\"avg_lrd_neigh\"}, axis = 1) avg_lrd.head() [8] 2021-04-26 11:40:48 ( 106ms ) python3 ( 1.51s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-15-d0f1691c03bf> in <module> 1 # Getting average LRD from all the neighbours ----> 2 avg_lrd = pd.merge(temp_2[['index_x', 'index_y']], lrd_all_pts, left_on = 'index_y', right_on = 'point_label', how = 'left') 3 avg_lrd = pd.DataFrame(avg_lrd.groupby(['index_x'])['lrd'].mean()).reset_index() 4 avg_lrd = avg_lrd.rename({\"index_x\":\"point_label\", \"lrd\":\"avg_lrd_neigh\"}, axis = 1) 5 Step 4: Calculate lof # Calculating LOF by dividing average LRD of neighbours to the actual LRD of the point lof = pd.merge(avg_lrd, lrd_all_pts, on = 'point_label', how = 'left') lof['lof'] = lof['avg_lrd_neigh']/ lof['lrd'] del lof['lrd'] del lof['avg_lrd_neigh'] lof.sort_values('lof', ascending = False)[:10] [9] 2021-04-26 11:40:48 ( 128ms ) python3 ( 1.64s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-16-dda84c93357d> in <module> 1 # Calculating LOF by dividing average LRD of neighbours to the actual LRD of the point ----> 2 lof = pd.merge(avg_lrd, lrd_all_pts, on = 'point_label', how = 'left') 3 lof['lof'] = lof['avg_lrd_neigh']/ lof['lrd'] 4 del lof['lrd'] 5 del lof['avg_lrd_neigh'] More the value of this LOF is higher, more the probablity of this point becoming an anomaly # Getting x and y coordinates for the given points lof_df = pd.merge(df[['x', 'y']].reset_index(), lof, left_on = 'index', right_on = 'point_label', how = 'left') del lof_df['index'] del lof_df['point_label'] lof_df.head() [10] 2021-04-26 11:40:48 ( 181ms ) python3 ( 1.82s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-17-4d1dc290ecc1> in <module> 1 # Getting x and y coordinates for the given points ----> 2 lof_df = pd.merge(df[['x', 'y']].reset_index(), lof, left_on = 'index', right_on = 'point_label', how = 'left') 3 del lof_df['index'] 4 del lof_df['point_label'] 5 thresh = 2 plt.scatter(lof_df[lof_df['lof'] > thresh]['x'], lof_df[lof_df['lof'] > thresh]['y']) plt.scatter(lof_df[lof_df['lof'] <= thresh]['x'], lof_df[lof_df['lof'] <= thresh]['y']) plt.show() [11] 2021-04-26 11:40:48 ( 106ms ) python3 ( 1.93s ) NameError: name 'plt' is not defined NameError Traceback (most recent call last) <ipython-input-18-4969c258b790> in <module> 1 thresh = 2 ----> 2 plt.scatter(lof_df[lof_df['lof'] > thresh]['x'], lof_df[lof_df['lof'] > thresh]['y']) 3 plt.scatter(lof_df[lof_df['lof'] <= thresh]['x'], lof_df[lof_df['lof'] <= thresh]['y']) 4 5 plt.show() Hyperparameter Selection How to select the correct K-value? Minimum K should be considered as the number of points which can be considered as a cluster, so that other clusters with less points can be considered outliers. When K < 10, LOF is highly volatile Max K should be selected as the points to be considered as outliers if clustered together Alternatives How to select the correct value for LOF User dependendent Disadvantages LOF < 1 is definitely an inlier but the inverse statement may not be as true strong local fluctuations may increase the number of false positives Alternatives can use feature bagging instead to reduce FP can use local outlier probability to reduce the chance of choosing the wrong K Why reachability distance is considered instead of euclidean distance?","title":"Local Outlier Factor"},{"location":"algorithms/clustering/local_outlier_detection/#introduction","text":"compares local density of the outliers to the local density of its K neighbours if a points local density is significantly lower than its K nearest neighbours, it can be called as an anomaly this density is calculated by the inverse of the reachability distance","title":"Introduction"},{"location":"algorithms/clustering/local_outlier_detection/#selection-criteria","text":"used when the anomaly is very close to the actual points but less densely packed will flag high density and sparse clusters as normal, but a loose point near a dense cluster as an anomaly","title":"Selection criteria"},{"location":"algorithms/clustering/local_outlier_detection/#how-it-works","text":"Considering a dataset which has already formed clusters import matplotlib.pyplot as plt import numpy as np import pandas as pd # Generate normal (not abnormal) training observations X = 0.3 * np.random.randn(100, 2) # create a normal distribution between 0 and 1 of the required shape X_train = np.r_[X + 2, X - 2] # concat multiple array's of the same shape together # Generate new normal (not abnormal) observations X = 0.3 * np.random.randn(20, 2) X_test = np.r_[X + 2, X - 2] # Generate some abnormal novel observations X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2)) df = pd.DataFrame(np.r_[X_train, X_test, X_outliers], columns = ['x', 'y']) df.head() [1] 2021-04-26 11:31:08 ( 104ms ) python3 ( 3.32s ) x y 0 1.448091 2.500459 1 1.589671 1.691205 2 2.283369 2.543845 3 2.314729 2.030218 4 2.248377 1.986990 plt.scatter(df['x'], df['y']) plt.show() [2] 2021-04-26 11:31:08 ( 190ms ) python3 ( 3.51s ) Step 1: Find K nearest datapoints using eucleidian distance from the point under consideration, we are assuming K to be 3 in this case # Getting indices for each of the point temp = df[['x', 'y']].reset_index() # Applying cross join to calculate Euclidean distance # Adding 0 column for cross join temp[0] = 0 temp = pd.merge(temp, temp, how = 'outer', on = 0) # Dropping 0 column del temp[0] # Calculating Euclidean distance temp['eu_dist'] = ((temp['x_x'] - temp['x_y'])**2 + (temp['y_x'] - temp['y_y'])**2)**0.5 # Dropping zero values because they will be same point temp = temp[temp['eu_dist'] != 0] # Adding a rank by distance to each datapoint to get the closest K datapoint temp[\"rank\"] = temp.groupby(\"index_x\")[\"eu_dist\"].rank(\"min\", ascending=True) #let k = 2 k = 3 temp = temp[temp['rank'] <=k] temp.head() [3] 2021-04-26 11:40:47 ( 139ms ) python3 ( 785ms ) NameError: name 'df' is not defined NameError Traceback (most recent call last) <ipython-input-10-8f43e2957478> in <module> 1 # Getting indices for each of the point ----> 2 temp = df[['x', 'y']].reset_index() 3 4 # Applying cross join to calculate Euclidean distance 5 # Adding 0 column for cross join Step 2: Calculate reachability distance from the considered point to its neighbours (which also equals the maximum distance between Kth distance of the other point or the euclidian distance of that point) # Sorting values to get the kth distance for each point temp_2 = temp.sort_values(['index_x', 'eu_dist'], ascending = [True,False]).reset_index(drop = True)[['index_x', 'index_y','eu_dist']] # Getting the kth value min_indices = [] for i in np.unique(np.array(temp_2['index_x'])): min_indices.append(min(temp_2[temp_2['index_x'] == i].index)) kth_distance = temp_2[temp_2.index.isin(min_indices)] kth_distance = kth_distance.rename(columns={\"eu_dist\": \"kth_dist\", \"index_x\": \"point_label\"}) del kth_distance['index_y'] kth_distance.head() [4] 2021-04-26 11:40:47 ( 255ms ) python3 ( 1.04s ) NameError: name 'temp' is not defined NameError Traceback (most recent call last) <ipython-input-11-a3e6eabb29b3> in <module> 1 # Sorting values to get the kth distance for each point ----> 2 temp_2 = temp.sort_values(['index_x', 'eu_dist'], ascending = [True,False]).reset_index(drop = True)[['index_x', 'index_y','eu_dist']] 3 4 # Getting the kth value 5 min_indices = [] # Calculating reachability distance reach_dist = pd.merge(temp_2, kth_distance, left_on = 'index_y', right_on= 'point_label', how = 'left') del reach_dist['point_label'] reach_dist['rd'] = reach_dist[['eu_dist','kth_dist']].max(axis = 1) del reach_dist['eu_dist'] del reach_dist['kth_dist'] reach_dist.head() [5] 2021-04-26 11:40:47 ( 157ms ) python3 ( 1.20s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-12-71b6a020d6dd> in <module> 1 # Calculating reachability distance ----> 2 reach_dist = pd.merge(temp_2, kth_distance, left_on = 'index_y', right_on= 'point_label', how = 'left') 3 del reach_dist['point_label'] 4 5 reach_dist['rd'] = reach_dist[['eu_dist','kth_dist']].max(axis = 1) mean_rd = pd.DataFrame(reach_dist.groupby(['index_x'])['rd'].mean()).reset_index() mean_rd = mean_rd.rename(columns={\"index_x\": \"point_label\"}) mean_rd.head() [6] 2021-04-26 11:40:47 ( 105ms ) python3 ( 1.30s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-13-637b1bcafcd4> in <module> ----> 1 mean_rd = pd.DataFrame(reach_dist.groupby(['index_x'])['rd'].mean()).reset_index() 2 3 mean_rd = mean_rd.rename(columns={\"index_x\": \"point_label\"}) 4 mean_rd.head() Step 3: Calculate local reachability density # Getting LRD(local reachability density) for individual points lrd_all_pts = mean_rd.copy() lrd_all_pts['lrd'] = 1/lrd_all_pts['rd'] del lrd_all_pts['rd'] lrd_all_pts.head() [7] 2021-04-26 11:40:47 ( 105ms ) python3 ( 1.41s ) NameError: name 'mean_rd' is not defined NameError Traceback (most recent call last) <ipython-input-14-9fc93de50496> in <module> 1 # Getting LRD(local reachability density) for individual points ----> 2 lrd_all_pts = mean_rd.copy() 3 lrd_all_pts['lrd'] = 1/lrd_all_pts['rd'] 4 del lrd_all_pts['rd'] 5 # Getting average LRD from all the neighbours avg_lrd = pd.merge(temp_2[['index_x', 'index_y']], lrd_all_pts, left_on = 'index_y', right_on = 'point_label', how = 'left') avg_lrd = pd.DataFrame(avg_lrd.groupby(['index_x'])['lrd'].mean()).reset_index() avg_lrd = avg_lrd.rename({\"index_x\":\"point_label\", \"lrd\":\"avg_lrd_neigh\"}, axis = 1) avg_lrd.head() [8] 2021-04-26 11:40:48 ( 106ms ) python3 ( 1.51s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-15-d0f1691c03bf> in <module> 1 # Getting average LRD from all the neighbours ----> 2 avg_lrd = pd.merge(temp_2[['index_x', 'index_y']], lrd_all_pts, left_on = 'index_y', right_on = 'point_label', how = 'left') 3 avg_lrd = pd.DataFrame(avg_lrd.groupby(['index_x'])['lrd'].mean()).reset_index() 4 avg_lrd = avg_lrd.rename({\"index_x\":\"point_label\", \"lrd\":\"avg_lrd_neigh\"}, axis = 1) 5 Step 4: Calculate lof # Calculating LOF by dividing average LRD of neighbours to the actual LRD of the point lof = pd.merge(avg_lrd, lrd_all_pts, on = 'point_label', how = 'left') lof['lof'] = lof['avg_lrd_neigh']/ lof['lrd'] del lof['lrd'] del lof['avg_lrd_neigh'] lof.sort_values('lof', ascending = False)[:10] [9] 2021-04-26 11:40:48 ( 128ms ) python3 ( 1.64s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-16-dda84c93357d> in <module> 1 # Calculating LOF by dividing average LRD of neighbours to the actual LRD of the point ----> 2 lof = pd.merge(avg_lrd, lrd_all_pts, on = 'point_label', how = 'left') 3 lof['lof'] = lof['avg_lrd_neigh']/ lof['lrd'] 4 del lof['lrd'] 5 del lof['avg_lrd_neigh'] More the value of this LOF is higher, more the probablity of this point becoming an anomaly # Getting x and y coordinates for the given points lof_df = pd.merge(df[['x', 'y']].reset_index(), lof, left_on = 'index', right_on = 'point_label', how = 'left') del lof_df['index'] del lof_df['point_label'] lof_df.head() [10] 2021-04-26 11:40:48 ( 181ms ) python3 ( 1.82s ) NameError: name 'pd' is not defined NameError Traceback (most recent call last) <ipython-input-17-4d1dc290ecc1> in <module> 1 # Getting x and y coordinates for the given points ----> 2 lof_df = pd.merge(df[['x', 'y']].reset_index(), lof, left_on = 'index', right_on = 'point_label', how = 'left') 3 del lof_df['index'] 4 del lof_df['point_label'] 5 thresh = 2 plt.scatter(lof_df[lof_df['lof'] > thresh]['x'], lof_df[lof_df['lof'] > thresh]['y']) plt.scatter(lof_df[lof_df['lof'] <= thresh]['x'], lof_df[lof_df['lof'] <= thresh]['y']) plt.show() [11] 2021-04-26 11:40:48 ( 106ms ) python3 ( 1.93s ) NameError: name 'plt' is not defined NameError Traceback (most recent call last) <ipython-input-18-4969c258b790> in <module> 1 thresh = 2 ----> 2 plt.scatter(lof_df[lof_df['lof'] > thresh]['x'], lof_df[lof_df['lof'] > thresh]['y']) 3 plt.scatter(lof_df[lof_df['lof'] <= thresh]['x'], lof_df[lof_df['lof'] <= thresh]['y']) 4 5 plt.show()","title":"How it works?"},{"location":"algorithms/clustering/local_outlier_detection/#hyperparameter-selection","text":"How to select the correct K-value? Minimum K should be considered as the number of points which can be considered as a cluster, so that other clusters with less points can be considered outliers. When K < 10, LOF is highly volatile Max K should be selected as the points to be considered as outliers if clustered together","title":"Hyperparameter Selection"},{"location":"algorithms/clustering/local_outlier_detection/#alternatives","text":"How to select the correct value for LOF User dependendent","title":"Alternatives"},{"location":"algorithms/clustering/local_outlier_detection/#disadvantages","text":"LOF < 1 is definitely an inlier but the inverse statement may not be as true strong local fluctuations may increase the number of false positives","title":"Disadvantages"},{"location":"algorithms/clustering/local_outlier_detection/#alternatives_1","text":"can use feature bagging instead to reduce FP can use local outlier probability to reduce the chance of choosing the wrong K Why reachability distance is considered instead of euclidean distance?","title":"Alternatives"}]}